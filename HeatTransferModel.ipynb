{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\stevenbc\\Anaconda3\\lib\\site-packages\\gym\\__init__.py:15: UserWarning: gym.undo_logger_setup is deprecated. gym no longer modifies the global logging configuration\n",
      "  warnings.warn(\"gym.undo_logger_setup is deprecated. gym no longer modifies the global logging configuration\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "WARNING:tensorflow:From C:\\Users\\stevenbc\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                688       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                340       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 1,572\n",
      "Trainable params: 1,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "observation_input (InputLayer)  (None, 1, 42)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "action_input (InputLayer)       (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 42)           0           observation_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 62)           0           action_input[0][0]               \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           2016        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           1056        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           1056        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            33          activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1)            0           dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,161\n",
      "Trainable params: 4,161\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\stevenbc\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\stevenbc\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1204: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\stevenbc\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import DDPGAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "\n",
    "ENV_NAME = 'CoolingFin-v0'\n",
    "gym.undo_logger_setup()\n",
    "\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "assert len(env.action_space.shape) == 1\n",
    "nb_actions = env.action_space.shape[0]\n",
    "\n",
    "# Next, we build a very simple model.\n",
    "actor = Sequential()\n",
    "actor.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "actor.add(Dense(16))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(16))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(16))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(nb_actions))\n",
    "actor.add(Activation('linear'))\n",
    "print(actor.summary())\n",
    "\n",
    "action_input = Input(shape=(nb_actions,), name='action_input')\n",
    "observation_input = Input(shape=(1,) + env.observation_space.shape, name='observation_input')\n",
    "flattened_observation = Flatten()(observation_input)\n",
    "x = Concatenate()([action_input, flattened_observation])\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(1)(x)\n",
    "x = Activation('linear')(x)\n",
    "critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "print(critic.summary())\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=100000, window_length=1)\n",
    "random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta=.15, mu=0., sigma=.3)\n",
    "agent = DDPGAgent(nb_actions=nb_actions, actor=actor, critic=critic, critic_action_input=action_input,\n",
    "                  memory=memory, nb_steps_warmup_critic=100, nb_steps_warmup_actor=100,\n",
    "                  random_process=random_process, gamma=.5, target_model_update=1e-3)\n",
    "agent.compile(Adam(lr=.0001, clipnorm=1.), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 5000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "500/500 [==============================] - 6s 11ms/step - reward: 51699.3693\n",
      "2 episodes - episode_reward: 8617706.312 [4217017.935, 13018394.690] - loss: 1100701516.204 - mean_absolute_error: 29220.968 - mean_q: 3122.647\n",
      "\n",
      "Interval 2 (500 steps performed)\n",
      "500/500 [==============================] - 5s 11ms/step - reward: 85586.3600\n",
      "3 episodes - episode_reward: 17135817.345 [17132095.418, 17141907.054] - loss: 819714880.000 - mean_absolute_error: 29902.082 - mean_q: 49054.848\n",
      "\n",
      "Interval 3 (1000 steps performed)\n",
      "500/500 [==============================] - 6s 12ms/step - reward: 84618.9833\n",
      "2 episodes - episode_reward: 16957943.521 [16783791.623, 17132095.418] - loss: 624456448.000 - mean_absolute_error: 24062.760 - mean_q: 73750.469\n",
      "\n",
      "Interval 4 (1500 steps performed)\n",
      "500/500 [==============================] - 8s 16ms/step - reward: 85063.7200\n",
      "3 episodes - episode_reward: 16975154.862 [16941485.421, 17016546.901] - loss: 505610656.000 - mean_absolute_error: 14962.451 - mean_q: 98231.336\n",
      "\n",
      "Interval 5 (2000 steps performed)\n",
      "500/500 [==============================] - 8s 15ms/step - reward: 56547.7631\n",
      "2 episodes - episode_reward: 14146590.485 [11344003.025, 16949177.944] - loss: 620141824.000 - mean_absolute_error: 14379.436 - mean_q: 120911.016\n",
      "\n",
      "Interval 6 (2500 steps performed)\n",
      "500/500 [==============================] - 6s 11ms/step - reward: -284.2676\n",
      "3 episodes - episode_reward: -53811.066 [-75388.205, -38951.427] - loss: 849599360.000 - mean_absolute_error: 17305.939 - mean_q: 121697.617\n",
      "\n",
      "Interval 7 (3000 steps performed)\n",
      "500/500 [==============================] - 5s 11ms/step - reward: -378.9458\n",
      "2 episodes - episode_reward: -75789.160 [-75789.160, -75789.160] - loss: 1094224768.000 - mean_absolute_error: 18964.354 - mean_q: 129903.352\n",
      "\n",
      "Interval 8 (3500 steps performed)\n",
      "500/500 [==============================] - 6s 11ms/step - reward: -363.5705\n",
      "3 episodes - episode_reward: -73226.613 [-76141.563, -71582.729] - loss: 1376123264.000 - mean_absolute_error: 19065.816 - mean_q: 140112.203\n",
      "\n",
      "Interval 9 (4000 steps performed)\n",
      "500/500 [==============================] - 6s 11ms/step - reward: -358.9214\n",
      "2 episodes - episode_reward: -73555.850 [-75475.891, -71635.809] - loss: 1724051584.000 - mean_absolute_error: 20848.898 - mean_q: 152341.406\n",
      "\n",
      "Interval 10 (4500 steps performed)\n",
      "500/500 [==============================] - 6s 12ms/step - reward: 18874.6339\n",
      "done, took 60.851 seconds\n"
     ]
    }
   ],
   "source": [
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "agent.fit(env, nb_steps=5000, log_interval=500,visualize=False, verbose=1, nb_max_episode_steps=200)\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "agent.save_weights('ddpg_{}_weights.h5f'.format(ENV_NAME), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: 7845391.894, steps: 200\n",
      "Episode 2: reward: 7845391.894, steps: 200\n",
      "Episode 3: reward: 7845391.894, steps: 200\n",
      "Episode 4: reward: 7845391.894, steps: 200\n",
      "Episode 5: reward: 7845391.894, steps: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11300668>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "agent.test(env, nb_episodes=5, visualize=False, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"observation_input:0\", shape=(?, 1, 42), dtype=float32)\n",
      "(42,)\n"
     ]
    }
   ],
   "source": [
    "print(observation_input)\n",
    "print(env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(agent.nb_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
